{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b0e9ae3",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-13T16:58:26.641291Z",
     "iopub.status.busy": "2024-08-13T16:58:26.640524Z",
     "iopub.status.idle": "2024-08-13T16:58:43.802809Z",
     "shell.execute_reply": "2024-08-13T16:58:43.801971Z"
    },
    "papermill": {
     "duration": 17.170804,
     "end_time": "2024-08-13T16:58:43.805084",
     "exception": false,
     "start_time": "2024-08-13T16:58:26.634280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.32.1)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.42.3)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.23.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.3)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.0)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.5.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.3\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "mkdir -p /kaggle/working/submission\n",
    "pip install bitsandbytes accelerate transformers torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c4768d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T16:58:43.821184Z",
     "iopub.status.busy": "2024-08-13T16:58:43.820902Z",
     "iopub.status.idle": "2024-08-13T16:58:43.836284Z",
     "shell.execute_reply": "2024-08-13T16:58:43.835354Z"
    },
    "papermill": {
     "duration": 0.025915,
     "end_time": "2024-08-13T16:58:43.838350",
     "exception": false,
     "start_time": "2024-08-13T16:58:43.812435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing submission/main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile submission/main.py\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from collections import Counter\n",
    "import re\n",
    "import torch\n",
    "from kaggle_secrets import UserSecretsClient\n",
    "import os\n",
    "import sys\n",
    "import shutil\n",
    "import bitsandbytes as bnb\n",
    "import accelerate\n",
    "from torch import bfloat16\n",
    "import random\n",
    "bnb_config = transformers.BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_quant_type='dynamic', \n",
    "    bnb_8bit_use_double_quant=True,\n",
    "    bnb_8bit_compute_dtype=torch.float32 \n",
    ")\n",
    "model_id = 'llama-3/transformers/8b-chat-hf/1'\n",
    "KAGGLE_AGENT_PATH = \"/kaggle_simulations/agent/\"\n",
    "if os.path.exists(KAGGLE_AGENT_PATH):\n",
    "    model_id = os.path.join(KAGGLE_AGENT_PATH, \"1\")\n",
    "else:\n",
    "    model_id = \"/kaggle/input/llama-3/transformers/8b-chat-hf/1\"\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map=\"auto\")\n",
    "config = model.config\n",
    "\n",
    "# Check relevant configuration settings\n",
    "print(\"MODEL/TOKENIZER INITIALIZED\")\n",
    "id_eot = tokenizer.convert_tokens_to_ids([\"<|eot_id|>\"])[0]\n",
    "\n",
    "\n",
    "questioner_sys_prompt_thing = \"\"\"You are the questioner agent with a sharp strategy for playing the game 20 questions. The goal is to ask questions to find a word thought of by the user, which falls into one of the following categories:\n",
    "         1. Food or drink items such as: Food, drinks, things relating to food and drinks such as oven, spoon, tablecloth, dinner table, and so on.\n",
    "         2. A living thing such as: A specific bug, mammal, fish, tree, plant, and many more.\n",
    "         3. An object that is electric such as: electric razor, water heater, lamp, washer, type of vehicle, other industrial items\n",
    "         4. Many other unique and specific items!\n",
    "        Employ smart questions to strategically reduce the search space:\n",
    "        - Ask questions related to use of the thing, purpose of the item, size of the item, color of the item, whether the thing is living, and so on.\n",
    "        - Ask questions about broad categories to narrow the search.\n",
    "        Remember, your aim is to use each question to progressively eliminate unlikely options, which the guesser agent will use to guess the keyword. \n",
    "        \"\"\"\n",
    "guesser_sys_prompt = \"\"\"You are an professional assistant with a sharp strategy for playing the game 20 questions and a large vocabulary. Your goal is to guess the word thought of by the user, which falls into one of the following categories:\n",
    "         1. Food or drink items such as: Food, drinks, things relating to food, beverages, or cooking such as oven, spoon, tablecloth, dinner table, and so on.\n",
    "         2. A living thing such as: A specific bug, mammal, fish, tree, plant, and many more\n",
    "         3. An object that is electric such as: electric razor, water heater, lamp, washer, type of vehicle\n",
    "         4. An object used for a specific purpose, such as a magnet, silicone, lighter, trimming scissors, and other odd items.\n",
    "        To play the game and win, you should use the history of the game, the questions and answers, to guess the keyword.\n",
    "        Remember, your aim is to give a unique guess after understanding the history of the game, leading to a precise guess of the keyword.\n",
    "        Some of the keyword are really specific and peculiar objects so be creative and really use the history to help you.\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "answerer_sys_prompt = \"\"\"You are an expert AI gamer with a sharp strategy for playing the game 20 questions, you will be the answerer. Your goal is to answer questions thought of by the user, about a keyword which falls into one of the following categories:\n",
    "        1. A specific thing (which will be food or drink items, things that can be bought at the store, items used around the house, or other specific things)\n",
    "\"\"\"\n",
    "\n",
    "few_shot_examples_thing = \"\"\"GAME 1: Keyword is Ironing Board in category Thing:\n",
    "\n",
    "Question 1: Does the keyword belong to the broad category of living things?\n",
    "Answer 1: No\n",
    "Guess 1: Magnet\n",
    "Question 2: Does the keyword belong to the broad category of Food or Drink items?\n",
    "Answer 2: No\n",
    "Guess 2: Electric Razor\n",
    "Question 3: Is the keyword used for a specific purpose?\n",
    "Answer 3: Yes\n",
    "Guess 3: Garbage Can\n",
    "Question 4: Is the keyword related to Entertainment or Sports?\n",
    "Answer 4: No\n",
    "Guess 4: Scissors\n",
    "Question 5: Is the keyword something related to cleaning at all?\n",
    "Answer 5: Yes\n",
    "Guess 5: Garden Hose\n",
    "Question 6: Is the keyword used to clean your body?\n",
    "Answer 6: No\n",
    "Guess 6: Bleach\n",
    "Question 7: Is the keyword used to clean clothes?\n",
    "Answer 7: Yes\n",
    "Guess 7: Laundry Detergent\n",
    "Question 8: Is the keyword used to clean stains out of clothes?\n",
    "Answer 8: No\n",
    "Guess 8: Ironing Board\n",
    "\n",
    "Correct!!\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "def generate_answer(template, mode, max_new_tokens=60):\n",
    "    temperature = 0.1\n",
    "\n",
    "    inp_ids = tokenizer(template, return_tensors=\"pt\").to(\"cuda\")\n",
    "    #print(f\"Input token length: {inp_ids.input_ids.shape[1]}\")\n",
    "    guess_temp = 0.1\n",
    "    ask_temp = 0.9\n",
    "    guess_temps = [0.1,0.1, 1.2, 0.7, 0.9]\n",
    "    answer_temps = [0.01, 0.1, 0.2, 0.4, 0.5]\n",
    "    if mode == 'ask':\n",
    "        temperature = ask_temp\n",
    "        max_new_tokens = 50\n",
    "    elif mode == 'guess':\n",
    "        temperature = random.choice(guess_temps)\n",
    "        print(\"GUESSER SELECTED TEMP\")\n",
    "        print(temperature)\n",
    "        max_new_tokens = 20\n",
    "    elif mode == 'answer':\n",
    "        temperature = random.choice(answer_temps)\n",
    "        print(\"ANSWER SELECTED TEMP\")\n",
    "        print(temperature)\n",
    "        max_new_tokens = 50\n",
    "\n",
    "    out_ids = model.generate(\n",
    "        **inp_ids,\n",
    "        do_sample=True,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_beams=3,\n",
    "        temperature=temperature\n",
    "    ).squeeze()\n",
    "    \n",
    "    start_gen = inp_ids.input_ids.shape[1]\n",
    "    out_ids = out_ids[start_gen:]\n",
    "\n",
    "    if id_eot in out_ids:\n",
    "        stop = out_ids.tolist().index(id_eot)\n",
    "        out = tokenizer.decode(out_ids[:stop])\n",
    "    else:\n",
    "        out = tokenizer.decode(out_ids)\n",
    "    print(\"RESPONSE HAS BEEN GENERATED\")\n",
    "    print(mode)\n",
    "    print(out)\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, few_shot_examples, sys_prompt: str = None):\n",
    "        self.sys_prompt = sys_prompt\n",
    "        self.few_shot_examples = None\n",
    "        #pass\n",
    "        \n",
    "    def get_agent(self, mode, obs):\n",
    "        if mode == 'ask':\n",
    "            output = self.questioner(obs)\n",
    "        if mode =='guess':\n",
    "            output = self.questioner(obs)\n",
    "        if mode == 'answer':\n",
    "            \n",
    "            output = self.answerer(obs)\n",
    "            \n",
    "            if \"yes\" in output.lower():\n",
    "                output = \"yes\"\n",
    "            elif \"no\" in output.lower():\n",
    "                output = \"no\"   \n",
    "            if (\"yes\" not in output.lower() and \"no\" not in output.lower()):\n",
    "                output = \"yes\"\n",
    "                \n",
    "        return output\n",
    "    \n",
    "    def answerer(self, obs):\n",
    "        previous_question = obs.questions[-1]\n",
    "        if(len(previous_question) > 500):\n",
    "            previous_question = previous_question[:499]\n",
    "\n",
    "        prompt = f\"\"\"\\\n",
    "            The keyword for this game is \"{obs.keyword}\" in the category [{obs.category}]\n",
    "            You are currently answering a question about the word above.\n",
    "\n",
    "            The next question is \"{obs.questions[-1]}\".\n",
    "            \n",
    "            Your task is to answer the above yes/no question and place your answer in the following format surrounded by double asterisks:\n",
    "            \n",
    "            Answer: **yes**/**no**\n",
    "\n",
    "            - Your response should be accurate given the keyword above\n",
    "            - Always respond with ONLY **yes** or **no**\n",
    "            \n",
    "            Now please tell me is the answer **yes** or **no** to the following question about {obs.keyword}: {previous_question}\n",
    "        \"\"\"\n",
    "        chat_template = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{prompt}<|eot_id|>\"\"\"\n",
    "        chat_template += \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "        responses = []\n",
    "        for i in range(3):\n",
    "            output = generate_answer(chat_template, mode='answer')\n",
    "            #output = parse_response(output)\n",
    "            #print()\n",
    "            if('yes' in output.lower()):\n",
    "                output = 'yes'\n",
    "            else:\n",
    "                output = 'no'\n",
    "            responses.append(output)\n",
    "        return most_common_answer(responses)\n",
    "\n",
    "\n",
    "        \n",
    "    def questioner(self, obs):\n",
    "        if obs.turnType == 'ask':\n",
    "            self.sys_prompt = questioner_sys_prompt_thing\n",
    "            self.few_shot_examples = few_shot_examples_thing\n",
    "                \n",
    "                \n",
    "            ask_prompt = f'Here is an example of how this game might work. \\n{self.few_shot_examples} \\n You will now ask questions relating to the keyword, your questions must be able to be responded to by yes or no. To help you, always try to bisect the search space with your questions. Please only say the question as verbosely and shortly as you can. ONLY STATE YOUR QUESTION WITHOUT EXPLANATION. Now ask a question.'\n",
    "            chat_template = f\"\"\"{self.sys_prompt}\\n{ask_prompt}\"\"\"\n",
    "            if len(obs.questions)>=1:\n",
    "       \n",
    "                for q, a in zip(obs.questions, obs.answers):\n",
    "                    chat_template += f\"{q}<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n\"\n",
    "                    chat_template += f\"{a}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "\n",
    "            output = generate_answer(chat_template, mode='ask')   \n",
    "        elif obs.turnType == \"guess\":\n",
    "            self.sys_prompt = guesser_sys_prompt\n",
    "            conv = \"\"\n",
    "            conv += self.sys_prompt + \"You will now guess the keyword. Here are the previous questions and answers:\\n <game_history>\"\n",
    "            for i, (q, a, g) in enumerate(zip(obs.questions, obs.answers, obs.guesses), start=1): \n",
    "                conv += f\"Question {i}: {q}\\nAnswer {i}: {a}\\nGuess {i}: {g}\\n\"\n",
    "            conv += '<game_history>'\n",
    "            guess_prompt =  f\"\"\"Here is a general understanding of the what game we are playing, and a description of the game history. \\n{conv}\n",
    "            based on the history of the game, guess the keyword. just say your guess and nothing else, short and verbose. Remember to use the previous questions/answers. \n",
    "            Here is an example of how the game might work: \\n{self.few_shot_examples}\\n\n",
    "            \n",
    "                - Now guess the keyword, just say your guess without explanation.\n",
    "                - Make sure your guess takes into account the history of the game, and gives a creative guess. \n",
    "                - Here are the previous guesses, DO NOT repeat guesses: {obs.guesses}\n",
    "                - IMPORTANT!!! DO NOT REPEAT GUESSES, BE SMART\n",
    "                \n",
    "                Place your guess in the following format:\n",
    "                Guess: example_guess\n",
    "                \n",
    "                \n",
    "            Now what is your guess? Be creative!\n",
    "            \"\"\"\n",
    "            chat_template = f\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\n{guess_prompt}<|eot_id|>\"\"\"\n",
    "            chat_template += \"<|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "            #output = generate_answer(chat_template, mode='guess')\n",
    "            responses = []\n",
    "            for i in range(5):\n",
    "                output = generate_answer(chat_template, mode='guess')\n",
    "                output_parsed = parse_after_colon(output)\n",
    "                responses.append(output_parsed)\n",
    "            output = most_common_answer(responses)\n",
    "        return output\n",
    "                \n",
    "        \n",
    "\n",
    "agent = Agent(few_shot_examples=None)\n",
    "\n",
    "def parse_response(input_string):\n",
    "    pattern = r'\\*\\*(.*?)\\*\\*'\n",
    "    matches = re.findall(pattern, input_string, re.DOTALL)\n",
    "    if matches:\n",
    "        return matches[0]\n",
    "    else:\n",
    "        return \"yes\"  \n",
    "def parse_after_colon(s):\n",
    "    match = re.search(r':\\s*(.*)', s)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return \"Cypress Knees\"\n",
    "def most_common_answer(answers):\n",
    "    counter = Counter(answers)\n",
    "\n",
    "    most_common = counter.most_common(1)[0][0]\n",
    "    return most_common\n",
    "def func1(keyword, question):\n",
    "    keyword_pattern = r\"^[a-zA-Z\\s]+$\"\n",
    "    question_pattern = r'^Does the keyword \\(in lowercase\\) precede \"([a-zA-Z\\s]+)\" in alphabetical order\\?$'\n",
    "    if not re.match(keyword_pattern, keyword) or not re.match(\n",
    "        question_pattern, question\n",
    "    ):\n",
    "        return None\n",
    "    match = re.match(question_pattern, question)\n",
    "    compare_word = match.group(1)\n",
    "    return keyword.lower() < compare_word.lower()#\n",
    "\n",
    "\n",
    "def func2(keyword, question):\n",
    "    question_pattern = 'Is it Agent Alpha?'\n",
    "    if question == question_pattern:\n",
    "        return 'Yes'\n",
    "    return None\n",
    "    \n",
    "def func3(keyword, question):\n",
    "    keyword_pattern = r\"^[a-zA-Z\\s]+$\"\n",
    "    question_patterns = [\n",
    "        r\"^Does the keyword start with one of the letters \\'([a-zA-Z]\\'(?:, \\'[a-zA-Z]\\')*)(?: or \\'[a-zA-Z]\\')?\\?$\",\n",
    "        r\"^Does the keyword start with the letter \\'([a-zA-Z])\\'\\?$\",\n",
    "    ]\n",
    "    if not re.match(keyword_pattern, keyword) or not any(\n",
    "        re.match(pattern, question) for pattern in question_patterns\n",
    "    ):\n",
    "        return None\n",
    "    if re.match(question_patterns[0], question):\n",
    "        letters = re.findall(r\"'([A-Z])'\", question)\n",
    "    else:\n",
    "        match = re.match(question_patterns[1], question)\n",
    "        letters = [match.group(1)]\n",
    "    letters = [c.lower() for c in letters]\n",
    "    return keyword.strip()[0].lower() in letters\n",
    "\n",
    "\n",
    "def func4(keyword, question):\n",
    "    keyword_pattern = r\"^[a-zA-Z\\s]+$\"\n",
    "    question_pattern = r\"^Is the keyword one of the following\\? ([a-zA-Z\\s,]+)\\?$\"\n",
    "    if not re.match(keyword_pattern, keyword) or not re.match(\n",
    "        question_pattern, question\n",
    "    ):\n",
    "        return None\n",
    "    match = re.match(question_pattern, question)\n",
    "    options = [option.strip() for option in match.group(1).split(\",\")]\n",
    "    return keyword.strip().lower() in [option.lower() for option in options]\n",
    "\n",
    "def func5(keyword, question):\n",
    "    keyword_pattern = r\"^[a-zA-Z\\s]+$\"\n",
    "    question_pattern = r\"^Considering every letter in the name of the keyword, does the name of the keyword include the letter \\'([A-Za-z])\\'\\?$\"\n",
    "    if not re.match(keyword_pattern, keyword) or not re.match(\n",
    "        question_pattern, question\n",
    "    ):\n",
    "        return None\n",
    "    match = re.match(question_pattern, question)\n",
    "    search_letter = match.group(1)\n",
    "    return search_letter.lower() in keyword.lower()\n",
    "\n",
    "\n",
    "def func(keyword, question):\n",
    "    solves = [func1, func2, func3, func4, func5]\n",
    "    for f in solves:\n",
    "        result = f(keyword, question)\n",
    "        if result is not None:\n",
    "            return result\n",
    "    return None\n",
    "\n",
    "def extract_text_after_colon(sentence):\n",
    "    match = re.search(r':\\s*(.*)', sentence)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return sentence\n",
    "    \n",
    "\n",
    "def agent_gameplay(obs, cfg):\n",
    "    response = None\n",
    "    if obs.turnType ==\"ask\":\n",
    "        if(len(obs.questions) < 1):\n",
    "            response = \"Is the keyword a living thing?\"\n",
    "        elif(len(obs.questions) == 1):\n",
    "            if(obs.answers[0].lower() == 'yes'):\n",
    "                response = \"Is the keyword a mammal?\"\n",
    "                print(response)\n",
    "            else:\n",
    "                response = \"Is the keyword related to Entertainment or Sports?\"\n",
    "                print(response)\n",
    "        else:\n",
    "            response = agent.get_agent(mode='ask', obs=obs)\n",
    "        \n",
    "    elif obs.turnType ==\"guess\":\n",
    "        response_initial = agent.get_agent(mode = \"guess\", obs= obs)\n",
    "        response = extract_text_after_colon(response_initial)\n",
    "    elif obs.turnType ==\"answer\":\n",
    "        check = func(obs.keyword, obs.questions[-1])\n",
    "        if(check is None):\n",
    "            response = agent.get_agent(mode ='answer', obs=obs)\n",
    "        else:\n",
    "            if(check):\n",
    "                response = \"yes\"\n",
    "            else:\n",
    "                response = \"no\"\n",
    "            \n",
    "    if response == None or len(response)<=1:\n",
    "        response = 'yes'\n",
    "        \n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e927eb8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T16:58:43.853463Z",
     "iopub.status.busy": "2024-08-13T16:58:43.853186Z",
     "iopub.status.idle": "2024-08-13T16:58:50.546238Z",
     "shell.execute_reply": "2024-08-13T16:58:50.545135Z"
    },
    "papermill": {
     "duration": 6.703536,
     "end_time": "2024-08-13T16:58:50.548829",
     "exception": false,
     "start_time": "2024-08-13T16:58:43.845293",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!apt install pigz pv > /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c5e5fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T16:58:50.565134Z",
     "iopub.status.busy": "2024-08-13T16:58:50.564778Z",
     "iopub.status.idle": "2024-08-13T17:04:32.871927Z",
     "shell.execute_reply": "2024-08-13T17:04:32.870813Z"
    },
    "papermill": {
     "duration": 342.318039,
     "end_time": "2024-08-13T17:04:32.874106",
     "exception": false,
     "start_time": "2024-08-13T16:58:50.556067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n"
     ]
    }
   ],
   "source": [
    "!tar --use-compress-program='pigz --fast --recursive | pv' -cf submission.tar.gz -C /kaggle/input/llama-3/transformers/8b-chat-hf . -C /kaggle/working/submission ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6afdb62a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:04:32.941538Z",
     "iopub.status.busy": "2024-08-13T17:04:32.941201Z",
     "iopub.status.idle": "2024-08-13T17:04:32.945592Z",
     "shell.execute_reply": "2024-08-13T17:04:32.944780Z"
    },
    "papermill": {
     "duration": 0.040401,
     "end_time": "2024-08-13T17:04:32.947540",
     "exception": false,
     "start_time": "2024-08-13T17:04:32.907139",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#def agent_dummy(obs, cfg):\n",
    "#    if obs.turnType == \"ask\":\n",
    "#        response = \"Is the keyword a Country in Europe?\"\n",
    "#    elif obs.turnType == \"guess\":\n",
    "#        response = \"duck\"\n",
    "#    elif obs.turnType == \"answer\":\n",
    "#        response = \"yes\"\n",
    "#    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea50b64f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:04:33.013953Z",
     "iopub.status.busy": "2024-08-13T17:04:33.013694Z",
     "iopub.status.idle": "2024-08-13T17:04:33.017694Z",
     "shell.execute_reply": "2024-08-13T17:04:33.016792Z"
    },
    "papermill": {
     "duration": 0.039316,
     "end_time": "2024-08-13T17:04:33.019511",
     "exception": false,
     "start_time": "2024-08-13T17:04:32.980195",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#debug_config = {'episodeSteps': 28,     # initial step plus 3 steps per round (ask/answer/guess)\n",
    "#                'actTimeout': 60,       # agent time per round in seconds; default is 60\n",
    "#               'runTimeout': 1200,      # max time for the episode in seconds; default is 1200                \n",
    "#'agentTimeout': 3600}  # obsolete field; default is 360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47e30a76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:04:33.085665Z",
     "iopub.status.busy": "2024-08-13T17:04:33.085373Z",
     "iopub.status.idle": "2024-08-13T17:04:33.089239Z",
     "shell.execute_reply": "2024-08-13T17:04:33.088433Z"
    },
    "papermill": {
     "duration": 0.039197,
     "end_time": "2024-08-13T17:04:33.091242",
     "exception": false,
     "start_time": "2024-08-13T17:04:33.052045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import kaggle_environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60746578",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:04:33.159546Z",
     "iopub.status.busy": "2024-08-13T17:04:33.159293Z",
     "iopub.status.idle": "2024-08-13T17:04:33.163187Z",
     "shell.execute_reply": "2024-08-13T17:04:33.162402Z"
    },
    "papermill": {
     "duration": 0.040012,
     "end_time": "2024-08-13T17:04:33.164894",
     "exception": false,
     "start_time": "2024-08-13T17:04:33.124882",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#keyword = \"Sieve\"\n",
    "#alts = []\n",
    "#kaggle_environments.envs.llm_20_questions.llm_20_questions.category = 'thing'\n",
    "#kaggle_environments.envs.llm_20_questions.llm_20_questions.keyword_obj = {'keyword':keyword,'alts':alts}\n",
    "#kaggle_environments.envs.llm_20_questions.llm_20_questions.keyword = keyword\n",
    "#kaggle_environments.envs.llm_20_questions.llm_20_questions.alts = alts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f63f2cc5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-13T17:04:33.231230Z",
     "iopub.status.busy": "2024-08-13T17:04:33.230976Z",
     "iopub.status.idle": "2024-08-13T17:04:33.234764Z",
     "shell.execute_reply": "2024-08-13T17:04:33.233981Z"
    },
    "papermill": {
     "duration": 0.038971,
     "end_time": "2024-08-13T17:04:33.236642",
     "exception": false,
     "start_time": "2024-08-13T17:04:33.197671",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#from kaggle_environments import make\n",
    "#path = '/kaggle/working/submission/main.py'\n",
    "#env = make(\"llm_20_questions\",configuration=debug_config, debug=True)\n",
    "#print('env created')\n",
    "#game_output = env.run(agents=[agent_gameplay, agent_gameplay, agent_dummy, agent_dummy])\n",
    "#env.render(mode=\"ipython\", width=600, height=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2686f405",
   "metadata": {
    "papermill": {
     "duration": 0.032405,
     "end_time": "2024-08-13T17:04:33.303292",
     "exception": false,
     "start_time": "2024-08-13T17:04:33.270887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb50377",
   "metadata": {
    "papermill": {
     "duration": 0.032509,
     "end_time": "2024-08-13T17:04:33.368790",
     "exception": false,
     "start_time": "2024-08-13T17:04:33.336281",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbdad15",
   "metadata": {
    "papermill": {
     "duration": 0.033133,
     "end_time": "2024-08-13T17:04:33.434290",
     "exception": false,
     "start_time": "2024-08-13T17:04:33.401157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 8550470,
     "sourceId": 61247,
     "sourceType": "competition"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 39106,
     "modelInstanceId": 28083,
     "sourceId": 33551,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30747,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 369.939141,
   "end_time": "2024-08-13T17:04:33.786797",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-13T16:58:23.847656",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
